{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b692c73",
   "metadata": {},
   "source": [
    "# Using Redis and OpenAI to chat with PDF documents\n",
    "\n",
    "This notebook demonstrates how to use RedisAI and (Azure) OpenAI to chat with PDF documents. The PDF included is\n",
    "a informational brochure about the Chevy Colorado pickup truck.\n",
    "\n",
    "In this notebook, we will use LLamaIndex to chunk, vectorize, and store the PDF document in Redis as vectors\n",
    "alongside associated text. The query interface provided by LLamaIndex will be used to search for relevant\n",
    "information given queries from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949e6cf1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redis\n",
      "  Downloading redis-5.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-3.17.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.35.0-py3-none-any.whl.metadata (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.1/123.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken\n",
      "  Downloading tiktoken-0.5.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.6 kB)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama_index==0.8.58\n",
      "  Downloading llama_index-0.8.58-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index==0.8.58) (2.0.22)\n",
      "Collecting aiostream<0.6.0,>=0.5.2 (from llama_index==0.8.58)\n",
      "  Downloading aiostream-0.5.2-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7 (from llama_index==0.8.58)\n",
      "  Downloading dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama_index==0.8.58)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama_index==0.8.58)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting langchain>=0.0.303 (from llama_index==0.8.58)\n",
      "  Downloading langchain-0.0.329-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.11/site-packages (from llama_index==0.8.58) (1.5.8)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama_index==0.8.58)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy (from llama_index==0.8.58)\n",
      "  Downloading numpy-1.26.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openai>=0.26.4 (from llama_index==0.8.58)\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pandas (from llama_index==0.8.58)\n",
      "  Downloading pandas-2.1.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (18 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from llama_index==0.8.58)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from llama_index==0.8.58) (4.8.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama_index==0.8.58)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting urllib3<2 (from llama_index==0.8.58)\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.10.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.14.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (8.16.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (5.11.2)\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->llama_index==0.8.58)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.9.3->llama_index==0.8.58)\n",
      "  Downloading wrapt-1.15.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain>=0.0.303->llama_index==0.8.58)\n",
      "  Downloading aiohttp-3.8.6-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (7.7 kB)\n",
      "Collecting anyio<4.0 (from langchain>=0.0.303->llama_index==0.8.58)\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain>=0.0.303->llama_index==0.8.58) (1.33)\n",
      "Collecting langsmith<0.1.0,>=0.0.52 (from langchain>=0.0.303->llama_index==0.8.58)\n",
      "  Downloading langsmith-0.0.56-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain>=0.0.303->llama_index==0.8.58)\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.6/158.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting click (from nltk<4.0.0,>=3.8.1->llama_index==0.8.58)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama_index==0.8.58)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama_index==0.8.58) (3.0.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama_index==0.8.58)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->llama_index==0.8.58) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->llama_index==0.8.58) (2023.3.post1)\n",
      "Collecting tzdata>=2022.1 (from pandas->llama_index==0.8.58)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index==0.8.58) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index==0.8.58)\n",
      "  Downloading multidict-6.0.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.1/120.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index==0.8.58)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index==0.8.58)\n",
      "  Downloading yarl-1.9.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (278 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index==0.8.58)\n",
      "  Downloading frozenlist-1.4.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index==0.8.58)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<4.0->langchain>=0.0.303->llama_index==0.8.58) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.303->llama_index==0.8.58) (2.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.8)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain>=0.0.303->llama_index==0.8.58)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic<3,>=1->langchain>=0.0.303->llama_index==0.8.58)\n",
      "  Downloading pydantic_core-2.10.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama_index==0.8.58) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Downloading llama_index-0.8.58-py3-none-any.whl (814 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m814.4/814.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading redis-5.0.1-py3-none-any.whl (250 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-3.17.0-py3-none-any.whl (277 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.4/277.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.5.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiostream-0.5.2-py3-none-any.whl (39 kB)\n",
      "Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.0.329-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (14.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.10.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (783 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m783.8/783.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading tokenizers-0.14.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading pandas-2.1.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.8.6-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.56-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.10.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (252 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.6/252.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wrapt, widgetsnbextension, urllib3, tzdata, tenacity, safetensors, regex, redis, python-dotenv, PyPDF2, pypdf, pydantic-core, numpy, mypy-extensions, multidict, marshmallow, jupyterlab-widgets, joblib, fsspec, frozenlist, filelock, click, async-timeout, anyio, annotated-types, aiostream, yarl, typing-inspect, pydantic, pandas, nltk, deprecated, aiosignal, tiktoken, langsmith, huggingface-hub, dataclasses-json, aiohttp, tokenizers, openai, langchain, ipywidgets, transformers, llama_index\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.7\n",
      "    Uninstalling urllib3-2.0.7:\n",
      "      Successfully uninstalled urllib3-2.0.7\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "Successfully installed PyPDF2-3.0.1 aiohttp-3.8.6 aiosignal-1.3.1 aiostream-0.5.2 annotated-types-0.6.0 anyio-3.7.1 async-timeout-4.0.3 click-8.1.7 dataclasses-json-0.5.14 deprecated-1.2.14 filelock-3.13.1 frozenlist-1.4.0 fsspec-2023.10.0 huggingface-hub-0.17.3 ipywidgets-8.1.1 joblib-1.3.2 jupyterlab-widgets-3.0.9 langchain-0.0.329 langsmith-0.0.56 llama_index-0.8.58 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 nltk-3.8.1 numpy-1.26.1 openai-0.28.1 pandas-2.1.2 pydantic-2.4.2 pydantic-core-2.10.1 pypdf-3.17.0 python-dotenv-1.0.0 redis-5.0.1 regex-2023.10.3 safetensors-0.4.0 tenacity-8.2.3 tiktoken-0.5.1 tokenizers-0.14.1 transformers-4.35.0 typing-inspect-0.9.0 tzdata-2023.3 urllib3-1.26.18 widgetsnbextension-4.0.9 wrapt-1.15.0 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the Python requirements\n",
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47264e32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:23.988789Z",
     "start_time": "2023-02-10T12:20:23.967877Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ") # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "import textwrap\n",
    "import openai\n",
    "\n",
    "from langchain.llms import AzureOpenAI, OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from llama_index.vector_stores import RedisVectorStore\n",
    "from llama_index import LangchainEmbedding\n",
    "from llama_index import (\n",
    "    GPTVectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    PromptHelper,\n",
    "    ServiceContext,\n",
    "    StorageContext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2014a346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the .env file in the parent directory into the current environment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./.env')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ad91218",
   "metadata": {},
   "source": [
    "# Azure OpenAI | OpenAI (direct)\n",
    "\n",
    "The notebook allows the user two choose between using the OpenAI and Azure OpenAI endpoints. Make sure to follow the instructions in the README and set the .env correctly according to whichever API you are using. \n",
    "\n",
    "NOTE: ONLY ONE API CAN BE USED AT A TIME.\n",
    "\n",
    "- **[Use Azure OpenAI](#Azure-OpenAI)**\n",
    "- **[Use OpenAI](#OpenAI) (direct)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0023333d",
   "metadata": {},
   "source": [
    "## Azure OpenAI \n",
    "\n",
    "Here we setup the AzureOpenAI models and API keys that we set by reading from the environment above. The ``PromptHelper`` sets the parameters for the OpenAI model. The classes defined here are used together to provide a QnA interface between the user and the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a77108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using models: text-embedding-ada-002 and gpt-35-turbo\n"
     ]
    }
   ],
   "source": [
    "# setup Llama Index to use Azure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Get the OpenAI model names ex. \"text-embedding-ada-002\"\n",
    "embedding_model = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "text_model = os.getenv(\"OPENAI_TEXT_MODEL\")\n",
    "\n",
    "\n",
    "print(f\"Using models: {embedding_model} and {text_model}\")\n",
    "\n",
    "# get the Azure Deployment name for the model\n",
    "embedding_model_deployment = os.getenv(\"AZURE_EMBED_MODEL_DEPLOYMENT_NAME\")\n",
    "text_model_deployment = os.getenv(\"AZURE_TEXT_MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(f\"Using deployments: {embedding_model_deployment} and {text_model_deployment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c67d58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = AzureOpenAI(deployment_name=text_model_deployment, model_kwargs={\n",
    "    \"api_key\": openai.api_key,\n",
    "    \"api_base\": openai.api_base,\n",
    "    \"api_type\": openai.api_type,\n",
    "    \"api_version\": openai.api_version,\n",
    "})\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "\n",
    "embedding_llm = LangchainEmbedding(\n",
    "    OpenAIEmbeddings(\n",
    "        model=embedding_model,\n",
    "        deployment=embedding_model_deployment,\n",
    "        openai_api_key= openai.api_key,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_type=openai.api_type,\n",
    "        openai_api_version=openai.api_version,\n",
    "    ),\n",
    "    embed_batch_size=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a31b8dae",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "The ``OpenAI`` class provides a simple interface to the OpenAI API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce97716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using models: text-embedding-ada-002 and gpt-35-turbo\n"
     ]
    }
   ],
   "source": [
    "# setup Llama Index to use Azure OpenAI\n",
    "openai.api_type = \"openai\"\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Get the OpenAI model names ex. \"text-embedding-ada-002\"\n",
    "embedding_model = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "text_model = os.getenv(\"OPENAI_TEXT_MODEL\")\n",
    "\n",
    "\n",
    "print(f\"Using models: {embedding_model} and {text_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "076cf33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LLM\n",
    "llm = OpenAI(model_kwargs={\n",
    "    \"api_key\": openai.api_key,\n",
    "    \"api_base\": openai.api_base,\n",
    "    \"api_type\": openai.api_type,\n",
    "    \"api_version\" : openai.api_version,\n",
    "})\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "\n",
    "# Set up Embedding model\n",
    "embedding_llm = LangchainEmbedding(\n",
    "    OpenAIEmbeddings(\n",
    "        model=embedding_model,\n",
    "        openai_api_version=openai.api_version,\n",
    "        openai_api_key= openai.api_key,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_type=openai.api_type,\n",
    "    ),\n",
    "    embed_batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff935d",
   "metadata": {},
   "source": [
    "### LLamaIndex\n",
    "\n",
    "[LlamaIndex](https://github.com/jerryjliu/llama_index) (GPT Index) is a project that provides a central interface to connect your LLM's with external data sources. It provides a simple interface to vectorize and store embeddings in Redis, create search indices using Redis, and perform vector search to find context for generative models like GPT.\n",
    "\n",
    "Here we will use it to load in the documents (Chevy Colorado Brochure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:30.175678Z",
     "start_time": "2023-02-10T12:20:30.172456Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: a881f312-28e8-4a66-9c37-fd1ee6f59651\n"
     ]
    }
   ],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader('./docs').load_data()\n",
    "print('Document ID:', documents[0].doc_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "697a59d2",
   "metadata": {},
   "source": [
    "Llamaindex also works with frameworks like langchain to make prompting and other aspects of a chat based application easier. Here we can use the ``PromptHelper`` class to help us generate prompts for the (Azure) OpenAI model. The will be off by default as it can be tricky to setup correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "147e7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of output tokens\n",
    "num_output = int(os.getenv(\"OPENAI_MAX_TOKENS\"))\n",
    "# max LLM token input size\n",
    "max_input_size = int(os.getenv(\"CHUNK_SIZE\"))\n",
    "# set maximum chunk overlap\n",
    "max_chunk_overlap = float(os.getenv(\"CHUNK_OVERLAP\"))\n",
    "\n",
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "132b7b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define the service we will use to answer questions\n",
    "# if you executive the Azure OpenAI code above, your Azure Models and creds will be used and the same for OpenAI\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor,\n",
    "    embed_model=embedding_llm,\n",
    "    prompt_helper=prompt_helper # uncomment to use prompt_helper.\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd270925",
   "metadata": {},
   "source": [
    "## Initialize Redis as a Vector Database\n",
    "\n",
    "Now we have our documents read in, we can initialize the ``RedisVectorStore``. This will allow us to store our vectors in Redis and create an index.\n",
    "\n",
    "The ``GPTVectorStoreIndex`` will then create the embeddings from the text chunks by calling out to OpenAI's API. The embeddings will be stored in Redis and an index will be created.\n",
    "\n",
    "NOTE: If you didn't set the ``OPENAI_API_KEY`` environment variable, you will get an error here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85f591-334a-492a-ba80-89fe7c79288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_redis_conn_from_env(using_ssl=False):\n",
    "    start = \"rediss://\" if using_ssl else \"redis://\"\n",
    "    # if using RBAC\n",
    "    password = os.getenv(\"REDIS_PASSWORD\", None)\n",
    "    username = os.getenv(\"REDIS_USERNAME\", \"default\")\n",
    "    if password != None:\n",
    "        start += f\"{username}:{password}@\"\n",
    "\n",
    "    return start + f\"{os.getenv('REDIS_ADDRESS')}:{os.getenv('REDIS_PORT')}\"\n",
    "\n",
    "\n",
    "# make using_ssl=True to use SSL with ACRE\n",
    "redis_address = format_redis_conn_from_env(using_ssl=False)\n",
    "print(f\"Using Redis address: {redis_address}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b0d59f-a7ac-413e-ab1f-3e46628d6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VectorStore\n",
    "vector_store = RedisVectorStore(\n",
    "    index_name=\"chevy_docs\",\n",
    "    index_prefix=\"blog\",\n",
    "    redis_url=redis_address,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# access the underlying client in the RedisVectorStore implementation to ping the redis instance\n",
    "vector_store.client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1558b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:33.735897Z",
     "start_time": "2023-02-10T12:20:30.404245Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Creating index chevy_docs\n",
      "Creating index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Added 27 documents to index chevy_docs\n",
      "Added 27 documents to index chevy_docs\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = GPTVectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04304299-fc3e-40a0-8600-f50c3292767e",
   "metadata": {},
   "source": [
    "## Start Querying information from the Document\n",
    "\n",
    "Now that we have our document stored in the index, we can ask questions against the index. The index will use the data stored in itself as the knowledge base for chatgpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35369eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:51.328762Z",
     "start_time": "2023-02-10T12:20:33.822688Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Using filters: *\n",
      "Using filters: *\n",
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog/vector_757363fb-fbb1-40b2-b2d3-980bc749014b', 'blog/vector_7605d028-5461-4390-ae28-5261bea48276']\n",
      "Found 2 results for query with id ['blog/vector_757363fb-fbb1-40b2-b2d3-980bc749014b', 'blog/vector_7605d028-5461-4390-ae28-5261bea48276']\n",
      "\n",
      "  The 2022 Chevrolet Colorado is available in two variants: an Extended Cab, Crew Cab Short Box, and\n",
      "a Crew Cab Long Box. Each variant offers a 2.5L DOHC 4-cylinder with Variable Valve Timing (VVT) and\n",
      "Direct Injection or a 3.6L DOHC V6 with Variable Valve Timing (VVT) and Direct Injection (Crew Cab\n",
      "4x4 and Crew Cab Long Box 2WD models). The transmission options for each variant are a 6-speed\n",
      "automatic, electronically controlled with overdrive or an 8-speed automatic, electronically\n",
      "controlled with overdrive, Tow/Haul mode, and Hitch Guidance 1 (Crew Cab 4x4 and Crew Cab Long Box\n",
      "2WD models). Additionally, the Crew Cab models are available with a Luxury Package which includes\n",
      "17\" Blade Silver Metallic-Painted Aluminum Wheels (standard on LT) and 18\" Dark Argent Metallic-\n",
      "Painted Aluminum Wheels (available on LT) or 18\" Black-Painted Aluminum Wheels with Red Accents\n",
      "(available on LT with Redline Edition). The Colorado is also available in a Bison Edition and with a\n",
      "variety of available accessories, including front and rear floor liners with AEV logo and AEV\n",
      "embroidered head restraints. To avoid\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What types of variants are available for the Chevrolet Colorado?\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99212d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:21:10.337294Z",
     "start_time": "2023-02-10T12:20:51.338718Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Using filters: *\n",
      "Using filters: *\n",
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog/vector_3e385d74-77c1-4397-8c4d-6018b4564c24', 'blog/vector_7605d028-5461-4390-ae28-5261bea48276']\n",
      "Found 2 results for query with id ['blog/vector_3e385d74-77c1-4397-8c4d-6018b4564c24', 'blog/vector_7605d028-5461-4390-ae28-5261bea48276']\n",
      "\n",
      "  The maximum towing capacity of the 2022 Chevrolet Colorado varies depending on the engine chosen.\n",
      "The 2.5L 4-cylinder engine has a towing capacity of 3,500 lbs., the 3.6L V6 engine has a towing\n",
      "capacity of 7,000 lbs., and the available GM-exclusive Duramax® 2.8L Turbo-Diesel engine has a\n",
      "maximum towing capacity of 7,700 lbs. It is also important to note that the vehicle has special\n",
      "features to aid in towing, such as winch provisions, an AEV rear bumper with recovery points, five\n",
      "AEV hot-stamped boron steel skid plates, AEV fender flares, fog lamps, front and rear floor liners\n",
      "with AEV logo, and AEV embroidered head restraints. The vehicle user interface is a product of Apple\n",
      "or Google, depending on your smartphone, and their terms and privacy statements apply. For Android\n",
      "users, you must have the Android Auto app on Google Play and a compatible Android smartphone. You\n",
      "can check which smartphones are compatible at the respective websites.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the maximum towing capacity of the chevy colorado?\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a028452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Using filters: *\n",
      "Using filters: *\n",
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog/vector_511739c5-28dc-4ed1-a130-d52e7e4104af', 'blog/vector_7605d028-5461-4390-ae28-5261bea48276']\n",
      "Found 2 results for query with id ['blog/vector_511739c5-28dc-4ed1-a130-d52e7e4104af', 'blog/vector_7605d028-5461-4390-ae28-5261bea48276']\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What are the main differences between the three engine types available for the Chevy Colorado?\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e73a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
